# 模型融合-5

这一部分原作者介绍了很多基础知识，我就省略了。主要有简单加权融合、stacking、blending、boosting和bagging

* 简单加权融合：就是把几个模型的预测结果按权重加和。
* stacking/blending：都是两层模型，stacking：第一层多个基模型交叉验证训练，第二次模型选用简单模型正常训练。blending：把数据集分成训练、验证和测试集，两层都正常训练。也没怎么用。
* boosting和bagging都在模型算法里做好了。

## 总结

自己就只用了原作者的两个模型简单加权融合，xgb和lgb的结果分别乘对应系数加和，系数就是谁验证集误差大，系数就小一点，最终提交结果。