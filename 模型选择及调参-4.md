# 模型选择及调参-4

主要就是测试模型的初始效果。

## 模型选择及基本测试

* 加载特征工程保存的数据。
* 对数据使用**内存减少函数**，这一步不必要但很好用，原作者祖传代码，主要是修改数据类型。
* 若还有异常值，处理一下，并且注意数据类型。

以下方法感觉不分前后顺序：

* 使用**线性模型**，使用前做归一化处理，训练模型后，可以查看对训练数据的拟合效果（散点图）。
* 观察**训练标签**，呈长尾分布，将`log`变换后的标签放入模型训练，操作同上。**不太懂。**
* 交叉验证观察作归一化和不做归一化的评价标准（`mae`）。**不太懂。**
* 模拟真实情况（分析适合题目的数据集划分），将训练集按时间划分，训练以前时间的数据，预测之后时间的数据。
* **绘制学习率曲线和验证曲线**
* 比较多种线性模型，这里起到一个特征筛选作用，主要使用`lr`、`ridge`、`lasso`回归，输出模型训练后的截距和权重参数（特征权重），绘图查看。比较前，简单划分出数值特征并对标签作归一化处理，这整一步都**没明白**。之后，交叉验证大致看看效果。
* 比较线性模型，主要是决策树、随机森林（速度慢的离谱）、梯度提升树、XGB、LGB和MLP，这一步没啥好说的，交叉验证看一下各模型效果。

## 调参

三种策略：贪心算法、网格搜索和贝叶斯优化。

* 贪心算法：主要就是把要找的参数列出来，然后手动依次查找最优参数，例如，先找到第一个参数的最优值，第二步固定第一个最优参数值，寻找第二个参数的最优值，后续依次在前者基础上寻找。效果一般。
* 网格搜索：速度巨慢，效果还行，但参数不能多。（`GridSearchCV`）
* 贝叶斯优化：据说效果最好，速度还快，但我用来没太明白。

## 总结

这一步也就是试试模型，没有太多要注意的，就是多用交叉验证，有个特征筛选不太明白。还有就是测出来效果好的是lgb和xgb，随机森林速度太慢了。迭代次数过多，容易过拟合。需要注意的是，基本上`sklearn`很多函数和模型都有，直接在测试中使用，但是参数太少了，而且不好观察调试信息，基本上xgb和lgb我习惯使用原生库，就是模型训练在数据上和参数上得按官方文档里的格式。